---
title: "01.import_format_data"
author: "Guillaume Papuga"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}
library (here)
library (tidyverse)
library (stringr)
library (raster)
library (mgrs)
```

# Introduction
## Article
Data processed in this file belongs to a project of ecological niche analysis of Convolvulus lanuginosus. 

## Format
This document is used to format data. No analysis is coded here.
All data names once processed follow the form d.something (d stands for "data", and the second part must clearly refer to the type of data).

# I. Micro-niche data ##> to be updated
```{r}
# load raw data
d.flore = read.csv(here::here("data","raw", "flore.convol_complet.csv"), sep = ";", dec = ",") # plant community
d.niche = read.csv(here::here("data","raw", "micro_niche.csv"), sep = ";", dec = ",") # micro niche
d.station = read.csv(here::here("data","raw", "info_station.csv"), sep = ";", dec = ",") # station

# calculate plat community index 

# join d.flore and d.niche
d.microniche
nb.row = nrow(d.microniche)

# write data in the "processed" folder
write.table (x = d.microniche, here::here("data","processed","d.microniche.txt"), sep = ";", dec = ".")
```
The *niche* dataset contains `r nb.row` populations.

# II. Ecological variables
```{r}
## define the path to the folder "Sentinel"
source = "/home/papuga/Documents/climate" # linux
```

## a. Download the base layer
```{r}
# Bioclim variables for current climate
## 1. Upload from computer
tile = list.files(path = paste(source, "/current/wc2.1_10m_bio", sep = "")) # names of each tile
cur.st = stack(paste(source, "/current/wc2.1_10m_bio/",tile, sep = ""))

## 2. Plot
plot(cur.st$wc2.1_10m_bio_1)
```

## b. Define the basic setting of raster layers
```{r layers setting}
## Set the basic parameters of the project
# each time you want to stack data, you have to respect the same PER : PROJECTION - EXTENT - RESOLUTION
# it's called the standard settings of the project.

# Same projection
p.proj = crs(cur.st)

# Same extent
p.extent = extent(cur.st)

# Same resolution 
p.res = res(cur.st)
```


## c. Stack other climate variables (Bioclim)
```{r}
# Ecological variables
## LGM
tile = list.files(path = paste(source, "/lgm/cclgmbi_10m", sep = "")) # names of each tile
lgm_cc.st = stack(paste(source, "/lgm/cclgmbi_10m/",tile, sep = "")) # stack the tiles

## LGM
tile = list.files(path = paste(source, "/lgm/mrlgmbi_10m", sep = "")) # names of each tile
lgm_mr.st = stack(paste(source, "/lgm/mrlgmbi_10m/",tile, sep = "")) # stack the tiles

## Mid Holocen
tile = list.files(path = paste(source, "/mid_holocen/ccmidbi_10m", sep = "")) # names of each tile
mid_cc.st = stack(paste(source, "/mid_holocen/ccmidbi_10m/",tile, sep = "")) # stack the tiles

## Mid olocen
tile = list.files(path = paste(source, "/mid_holocen/mrmidbi_10m", sep = "")) # names of each tile
mid_mr.st = stack(paste(source, "/mid_holocen/mrmidbi_10m/",tile, sep = "")) # stack the tiles

## Plot
# to be done
```


# III. Occurences (databases)
The aim of this section is to build a database of occurence throughout the two species range in order to compute their climatic niche based on WorldClim data. 

## 1. Dataset structure
```{r}
# The matrix is named `d.occ` and must contain 6 columns
# code.pop : population code (dataset specific)
# sp.name : species names (Convolvulus lanuginosus)
# presence : 1-0 for presence-(pseudo)absence
# date : the date (yyyymmdd)
# x : coordinate on the x-axis (longitude in decimal degree)
# y : coordinate on the y-axis (latitude in decimal degree)
# precision : precision of the location (expressed in meter)
# source : explicit name of the source of the imported dataset

d.occ.raw = as.data.frame(matrix (ncol = 8,nrow = 0))
colnames (d.occ.raw) = c("code.pop", "sp.name", "presence", "date", "x", "y", "precision", "source")
```

## 2. Import
To date, we have gathered four datasets.

### 2a. CBN data
```{r}
# load raw data
data.cbn = read.csv(here::here("data","raw", "export_360_28012020_cbnmed.csv"), sep = "\t", dec = ".")

# select correct columns
d.occ.cbn = data.cbn %>%
  mutate (presence = 1) %>%
  mutate (source = "cbnmed") %>%
  dplyr::select(c(id_observation, nom_reconnu, presence, date_releve_fin, lon_wgs84, lat_wgs84, id_precision, source)) %>%
  mutate(id_precision = case_when(id_precision  == 'P' ~ 10,
                                  id_precision  == 'T' ~ 500,
                                  id_precision  == 'C' ~ 10000,
                                  id_precision  == 'N' ~ 10000)) %>%
  rename (code.pop = id_observation, 
          sp.name = nom_reconnu, 
          date = date_releve_fin, 
          x = lon_wgs84, 
          y = lat_wgs84, 
          precision = id_precision)

# process & correct
d.occ.cbn = unique (d.occ.cbn) # delete duplicates

# change the format of the date

## filter for the date and the precision
d.occ.cbn = d.occ.cbn %>%
  drop_na() %>% # remove NA
  filter (precision < 1001)# precision
  # date


## count observation
nb.row = nrow(d.occ.cbn)
```

This dataset contains `r nb.row` populations.

### 2b. iNat
```{r}
# load raw data
data.inat = read.csv(here::here("data","raw", "occ.inat.convol_lan.200120.csv"), sep = ";", dec = ".")

# select correct columns
d.occ.inat = data.inat %>%
  mutate (presence = 1) %>%
  mutate (source = "inat") %>%
  dplyr::select(c(id, scientific_name, presence, observed_on, longitude, latitude, positional_accuracy, source)) %>%
  rename (code.pop = id, 
          sp.name = scientific_name, 
          date = observed_on, 
          x = longitude, 
          y = latitude, 
          precision = positional_accuracy) %>%
  replace_na(list(precision = 5)) # consider that obs without precision are camera based GPS obs


# process & correct
d.occ.inat = unique (d.occ.inat) # delete duplicates

# change the format of the date

## filter for the date and the precision
d.occ.inat = d.occ.inat %>%
  drop_na() %>% # remove NA
  filter (precision < 1001)# precision
  # date


## count observation
nb.row = nrow(d.occ.inat)
```

The iNaturalist dataset contains `r nb.row` populations.

### 2c. Anthos
```{r}
# load raw data
data.anthos = read.csv(here::here("data","raw", "convol_anthos.csv"), sep = ";", dec = ".")
coord = mgrs_to_latlng (as.vector(data.anthos$utm))

# select correct columns
d.occ.anthos = data.anthos %>%
  mutate (presence = 1) %>%
  mutate (source = "anthos") %>%
  unite (sp.name, c(agenero, aespecie), sep = " ") %>%
  mutate (x = as.numeric(coord$lng)) %>%
  mutate (y = as.numeric(coord$lat)) %>%
  mutate (precision = (mgrs_precision(as.vector(data.anthos$utm)))$precision) %>%
  dplyr::select(c(id_cita, sp.name, presence, X.4, x, y, precision, source)) %>%
  rename (code.pop = id_cita, 
          date = X.4)
  
# process & correct
d.occ.anthos = unique (d.occ.anthos) # delete duplicates

# change the format of the date

## filter for the date and the precision
d.occ.anthos = d.occ.anthos %>%
  drop_na() %>% # remove NA
  filter (precision < 1001)# precision
  # date


## count observation
nb.row = nrow(d.occ.anthos)
```
The Anthos dataset contains `r nb.row` populations.

### 2d. Valenciana
### 2e. Catalunya
### 2f. GBIF
```{r}
# load raw data
data.gbif = read.csv(here::here("data","raw", "0000607-200127171203522", "occurrence.csv"), sep = "\t", dec = ".")

# select correct columns
d.occ.gbif = data.gbif %>%
  mutate (presence = 1) %>%
  mutate (source = "gbif") %>%
  dplyr::select(c(gbifID, acceptedScientificName, presence, eventDate, decimalLongitude, decimalLatitude, coordinatePrecision, source)) %>%
  mutate (decimalLongitude = as.numeric(decimalLongitude)) %>%
  mutate (decimalLatitude = as.numeric(decimalLatitude)) %>%
  rename (code.pop = gbifID, 
          sp.name = acceptedScientificName, 
          date = eventDate, 
          x = decimalLongitude, 
          y = decimalLatitude, 
          precision = coordinatePrecision)
  
# process & correct
d.occ.gbif = unique (d.occ.gbif) # delete duplicates

# change the format of the date

## filter for the date and the precision
d.occ.gbif = d.occ.gbif %>%
  drop_na() %>% # remove NA
  filter (precision < 1001)# precision
  # date

## count observation
nb.row = nrow(d.occ.gbif)
```
The GBIF dataset contains `r nb.row` populations.

## 3. Synthesis
```{r}
# Copy and paste each dataset on the basic matrix
d.occ = rbind(d.occ.raw, 
              d.occ.cbn, 
              d.occ.anthos,
              d.occ.gbif,
              d.occ.inat)

# Eliminate double occurence in a signel cell
d.occ = d.occ %>%
  mutate (cell = cellFromXY(cur.st$wc2.1_10m_bio_1, d.occ[,c("x", "y")])) %>%
  distinct(cell)

# write data in the "processed" folder
write.table (x = d.occ, here::here("data","processed","d.occ.conv.lan.txt"), sep = ";", dec = ".")
```

## 4. Pseudo-absences
```{r pseudo-abs}
# Create a background area and sample bg points


# Draw an area where to sample pseudo-absence (projection area)
buff.pa = buffer(d.occ, width = 200*1000) # 200 * 1000m buffer
r = mask(ecov, buff.pa)

######

x <- reclassify(ept.raster, cbind(min(values (ept.raster), na.rm =T), 
                                  max(values (ept.raster), na.rm =T), 
                                  1), 
                right=FALSE)
x[is.na(x[])] <- 0 
y = rasterToContour(x)

buff.pa.c = crop (buff.pa, y)

ept.raster[ept.raster != NA] = 1


max(values (ept.raster), na.rm =T)

r <- raster(ncol=10, nrow=10)
values(r) <- rnorm(100)

x = reclassify(x, cbind(-Inf, 0.9, 0), right=FALSE)


# Create pseudo-absence data
random.Spoints = spsample(sard, 200, type="random") # spsample echantillonne dans un "SpatialPolygon"

# choisit un raster qu'on utilise pour ne selectionner qu'un point par "cell"
mask = stk$bio1
cells = cellFromXY(mask, random.Spoints) # cellFrom permet de récuperer les numéros des cellules avec toute sorte de fichier (XY, ligne, polygone, etc.)
cells <- unique(cells)

# enlever les valeurs doublons avec les cellules contenant l'espèce
cells.p = cellFromXY(mask, pts [, c("x", "y")]) # récupérer les cellules de présence
cells.p = unique(cells.p) 
cells = setdiff(cells, cells.p) # enlève les points communs aux deux
xy = xyFromCell(mask, cells) # récupère les coordonnées des cellules de mask dont le n° correspond a cell

random.Spoints = data.frame(xy) # reprend le mm nom que sur méthode avant pour pseudo absence
coordinates(random.Spoints) = ~x+y # set spatial coordinates to create a Spatial object
projection(random.Spoints) = CRS('+proj=longlat +datum=WGS84') # set the coordinate reference system (CRS)
```


# IV. Crop dataset to the study area

## a. Preset
```{r plot extent}
# due to the spatial extent of the project, it is difficult to map results
# define a local extent to visualize a subset of results (Frontignan, Hérault, France)
ext.fronti = extent (756670, 768435, 6257688, 6267642)
ext.practice = extent (762364.9, 803269.3, 6256546, 6286295 )
```

```{r open layers}
# Read layers (to avoid running the whole script when session restarts)
hydroperiod.93 = raster("/home/papuga/Documents/couches_lag.temp/processed_layers/hydroperiod.93.tif")
msavi.93 = raster("/home/papuga/Documents/couches_lag.temp/processed_layers/msavi.93.tif")
altitude.93.c.adj = raster("/home/papuga/Documents/couches_lag.temp/processed_layers/altitude.93.c.adj.tif")

## Stack all files together
## This is a way to check that everything has been done carefully and raster layers are compatible
ecov = stack (hydroperiod.93, 
              msavi.93,
              altitude.93.c.adj)

# crop to spatial extent
st = Sys.time()
lim = as(p.bound, Class = "Spatial")
ecov.m = raster::mask(ecov, lim)
ecov.c = raster::crop (ecov.m, lim)
end = Sys.time()
t1 = end-st

# crop to training area
st = Sys.time()
ecov.p = raster::crop (ecov, ext.practice)
end = Sys.time()
t1 = end-st
```

